---
title: "Preprocessing of LC-MS data with *xcms*"
format:
  html:
    toc: true
    self-contained: true
author: "Philippine Louail, Marilyn De Graeve, Johannes Rainer"
code_folding: hide
editor: source
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

```{r setup, include=FALSE}
library(knitr)
library(quarto)
library(BiocStyle)
knitr::opts_knit$set(root.dir = './')
```


# Introduction 
## Dataset description

This document outlines the preprocessing steps for an untargeted LC-MS/MS
metabolomics dataset. The samples consist of pooled human serum, each spiked
with known compounds at two different concentrations. These two different 
concentration are categorized as high vs low. Each sample was measured three 
times to ensure reproducibility.

Alongside the LC-MS data used for quantification, additional LC-MS/MS data was
acquired for each sample using a data-dependent acquisition (DDA) method.

## Data analysis description

In this workflow a LC-MS/MS data is processed with ...

This workflow processes LC-MS/MS data using a combination of R packages
designed for metabolomics analysis.

-   `Spectra` handles the raw mass spectrometry data.

-   `MsExperiment` manages the experimental design and links sample metadata
    with the raw data.

-   `xcms` performs the preprocessing steps, such as peak detection, alignment,
    and grouping.

-   Additional packages are used for plotting, loading data tables, and utility
    functions.

**note**: idk how references work for books but we could link to the xcms
preprint, it will be out by the time this is submitted. each preprocessing step
is handled by the xcms package

# Data import

```{r}
#| message: false
library(xcms)
library(MsExperiment)
library(Spectra)
library(readxl)
library(RColorBrewer)
library(pheatmap)
library(MetaboCoreUtils)
```

-   Load the xlsx file with the sample information
-   **Note**: we would ideally need to submit this data to MetaboLights. TODO:
    prepare the files to submit.
-   **Note**: for the book chapter it might actually be better to describe how
    to create and format a *sample* xlsx sheet to import the data - for the
    reproducible workflow (this document) it would be better to import from
    MetaboLights.
      - add some definition on the columns info (collision energy, 
      concentration ,..)

```{r}
std_spiked <- read_xlsx("data/standards.xlsx") |> as.data.frame()
std_files <- read_xlsx("data/standards_mzml.xlsx") |> as.data.frame()
std_files <- std_files[std_files$polarity == "POS", ]
MZML_PATH <- file.path("data/mzML/")

#' Prepare path to the files
std_files <- std_files[grep("Mix13", std_files$mzML), ]

#' Linking the raw data to its respective metadata. 
std_data <- readMsExperiment(file.path(MZML_PATH, std_files$mzML),
                             sampleData = std_files)
```

The current data set consists of the files and samples listed in the table
below.

```{r update-phenodata}
#| tbl-cap: "Data files and samples."
sampleData(std_data)[, c("mzML", "sample_name", "mode", "collision_energy",
                         "concentration")] |>
    kable(format = "pipe")
```

In order to make the analysis more efficient we will set up parallel processing
and using 2 cores. This will allows to process 2 samples at a time. The same
number need to thenbe input in the parameter `chunkSize =` during the main
preprocessing steps. For more info see xxx:

```{r}
cores <- 2
#' Set up parallel processing using 2 cores
if (.Platform$OS.type == "unix") {
    register(MulticoreParam(cores))
} else {
    register(SnowParam(cores))
}
```

# Initial data inspection

## Overview of full data

-   Describe why we should do that.

```{r}
bpc <- chromatogram(std_data, aggregationFun = "max")

#' Define colors
col_concentration <- c(low = "#FF7F00", high = "#A65628")
col_sample <- col_concentration[sampleData(std_data)$concentration]

plot(bpc, col = paste0(col_sample, 80))
grid()
abline(v = c(15, 225), lty = 2)
```

We filter the data set by retention time to focus on the part of the
chromatography where compounds get actually separated.

```{r}
std_data <- filterSpectra(std_data, filterRt, c(15, 225))
```

We extract again the BPC.

```{r}
bpc <- chromatogram(std_data, aggregationFun = "max")
plot(bpc, col = paste0(col_sample, 80))
grid()
legend("topright", col = col_concentration, lty = 1,
       legend = names(col_concentration))
```

We can see differences, in particular, two high intensity abundance files have
shifted or additional signal at around 130 seconds. 


## Extracting EICs for known compounds

- introduce that "we show above how to get an overview of the chromatographic 
  data, now we will zoom in on specific mz and rt areas." 
- we show how to extract the eic of a "known" compound : proline
  - precise that user should: approx 10 variable compounds 
  (eg AA, more hydrophobic, bigger, small), either known or unknown compound
  - say that this also allows us to estimate parameters for peak detection

```{r}
proline_formula <- "C5H9NO2"
proline_mass <- calculateMass(proline_formula)

proline_mz <- mass2mz(proline_mass, c("[M+H]+", "[M+NH4]+", "[M+H-CH2O2]+"))[1, ]
proline_mzr <- cbind(mzmin = proline_mz - 0.01, mzmax = proline_mz + 0.01)

proline_eic <- chromatogram(std_data, mz = proline_mzr)

plot(proline_eic, col = paste0(col_sample, 80))
```

Signal is not that clear. We zoom into the region to get more information.

```{r}
plot(proline_eic, col = paste0(col_sample, 80), xlim = c(140, 200))
```

Pretty tricky situation... not clear which signal it might be. maybe the one
around 190 seconds?

```{r}
plot(proline_eic, col = paste0(col_sample, 80), xlim = c(185, 195))
```

If this is supposed to be proline 

- why does the intensity of the signal differ
between low and high??? So, most likely this is **not** proline. What about the
signal at around 170:

```{r}
plot(proline_eic, col = paste0(col_sample, 80), xlim = c(165, 175))
```

This seems to make more sense...
**Notes**: I would justify the results above to subset the `proline_eic` 
vairable to only samples where we see the peaks. 
ALso i would keep the explanation of the 2 peaks and discuss it with the `bw`
param later down. even if they are far apart it still can be used i think. 


We can also visualize the individual mass peaks for the \[M+H\]+ ion in the
first sample.

- check if data properly centroided

```{r}
std_data_sub <- std_data[1] |>
    filterSpectra(filterRt, c(167, 172)) |>
    filterSpectra(filterMzRange, proline_mzr[1, ])

plot(std_data_sub)
```

Above we visualize individual mass peaks in the m/z - retention time plane: evaluate
  whether data is in centroid mode and allows to determine variance in peaks'
  m/z along retention time axis.

 


```{r}
mz_diff <- spectra(std_data_sub) |>
    mz() |>
    unlist() |>
    diff()

max(mz_diff)
#' expressed in ppm...
```

-   Use this information to determine rt width and m/z deviation. e.g. `ppm=` ï¿½
    parameter for peak picking.


# Data preprocessing

## Chromatographic peak detection

-   Derive settings: use the information from previous section. `peakwidth`:
    from the rule of thumb: half of the observed peak width to max double.
    Also, don't have too wise peak width.
-   `ppm` parameter: from above.
-   CentWave works with most LC-setups.

Peakwidth seems to be between 3-5 seconds. So we go for `peakwidth = c(2, 8)`

Difference between `integrate = 1` and `integrate = 2`? Should we mention that
or is it too much info/detail? 

- We should just precise that we use = 2 because gaussian-ish shape.

- mention low snstresth

Same for proline:

```{r}
cwp <- CentWaveParam(peakwidth = c(2, 8), integrate = 2, snthresh = 1) 

proline_eic <- findChromPeaks(proline_eic, param = cwp)
chromPeaks(proline_eic)

plot(proline_eic,
     peakCol = paste0(col_sample[chromPeaks(proline_eic)[, "column"]], 80),
     peakBg = paste0(col_sample[chromPeaks(proline_eic)[, "column"]], 40),
     col = col_sample, xlim = c(165, 180))
```

-  Explain why we use `snthresh = 5` instead of the default `snthresh = 10`.
    -   Because we have low intensity peaks, and we want to detect them.

```{r}
cwp <- CentWaveParam(peakwidth = c(2, 8),
                     ppm = 40,
                     snthresh = 5,
                     integrate = 2)
std_data <- findChromPeaks(std_data, param = cwp, chunkSize = cores)
```

Do peak refinement. Just mention in text that it is
suggested.because artifact artifact can be created, refinement
would fix that. 

-   Performing peak merging.

```{r}
mnpp <- MergeNeighboringPeaksParam(expandRt = 3, expandMz = 0.002, ppm = 10,
                                   minProp = 0.8)
std_data <- refineChromPeaks(std_data, mnpp, chunkSize = cores)
```

-   Summary of identified peaks:
    -   number of peaks per sample.
    -   quantiles of retention time widths, m/z widths.

```{r}
#' Summary of identified peaks
data.frame(sample_name = sampleData(std_data)$sample_name,
           peak_count = as.integer(table(chromPeaks(std_data)[, "sample"]))) |>
  t() |>
  kable(format = "pipe")
```

## Retention time alignment

-   Initial correspondence: check settings. Serine might be great, because
    there is some shift.
    -   describe `bw` parameter: bandwidth for the peak density estimation.
        this can be looser in the initial correspondence step for alignment.

**Notes** Proline is a good example.

```{r}
grp <- sampleData(std_data)$concentration
grp[sampleData(std_data)$mode == "DDA"] <- NA
pdp <- PeakDensityParam(sampleGroups = grp,
                        bw = 4,
                        minFraction = 2/3,
                        binSize = 0.02,
                        ppm = 20)

a <- filterRt(proline_eic[1, ], c(160, 200))
plotChromPeakDensity(a[1, ], pdp)
```

-   For retention time alignment the grouping of chrom peaks to features does
    not need to be perfect, i.e. it is OK if signal from different ions is
    grouped into the same feature. We just use the feature's retention time to
    correct for (systematic) shifts in retention time between samples.
-   Settings OK because we group the rt-shifted chrom peaks into the same
    feature.

Apply settings.

```{r}
#' Initial correspondence
std_data <- groupChromPeaks(std_data, pdp)
```

-   Alignment. Explain parameter `span`... `extraPeaks` and `minFraction` used
    to define the *anchor peaks*, `extraPeaks`: number of peaks per feature,
    should be large. `minFraction`...

```{r}
pgp <- PeakGroupsParam(minFraction = 6 / 8, extraPeaks = 50, span = 0.4)
std_data <- adjustRtime(std_data, pgp, chunkSize = cores)

plotAdjustedRtime(std_data)

bpc_adj <- chromatogram(std_data, chromPeaks = "none", aggregationFun = "max")

par(mfrow = c(2, 1))
plot(bpc, col = paste0(col_sample, 60))
grid()
plot(bpc_adj, col = paste0(col_sample, 60))
grid()
```

Hm, does not seem to be particularly good. Let's extract the serine and proline
again. 

- we can describe that is seem to be working up until 180s but after
  that not really. 
- what could be the potential steps to fix this (finding anchor peaks in that 
  area) but i would live it at that. 
  - then check in proline example.

```{r}
proline_eic_adj <- chromatogram(std_data, mz = proline_mzr)

par(mfrow = c(2, 1))
plot(proline_eic[1, ], col = paste0(col_sample, 80),
     peakType = "none", xlim = c(160, 200))
plot(proline_eic_adj[1, ], col = paste0(col_sample, 80),
     peakType = "none", xlim = c(160, 200))
```

Signal, including MS2 seems to be better aligned.

We then apply these retention time.

```{r}
std_data <- applyAdjustedRtime(std_data)
```


Quantify similarity of BPC between samples.

## Correspondence analysis

For correspondence, use now more stringent settings for retention time
differences. 

- mention `bw` here again, and that it should be stricter than in
the alignment step. e.g. because we expect the peaks of one feature to be closer
to eachother.

-   explain we are testing the new parameters below
-   explain the `simulate` parameter.

```{r}
pdp <- PeakDensityParam(sampleGroups = grp,
                        bw = 3,
                        minFraction = 2/3,
                        binSize = 0.02,
                        ppm = 20)

proline_eic_adj <- chromatogram(std_data, mz = proline_mzr, rt =
                                  cbind(rep(150, 3), rep(200, 3)))

plotChromPeakDensity(proline_eic_adj[1, ], param= pdp,  simulate = FALSE)
```
Nice grouping so we apply to full data:

```{r}
std_data <- groupChromPeaks(std_data, pdp)
```


## Gap filling

```{r}
sum(is.na(featureValues(std_data)))

std_data <- fillChromPeaks(std_data, ChromPeakAreaParam())
sum(is.na(featureValues(std_data)))
```

Compare filled data to detected values.

```{r}
det <- featureValues(std_data, filled = FALSE)
fil <- featureValues(std_data)
fil[!is.na(det)] <- NA

boxplot(log2(det))
boxplot(log2(fil))
```

**Notes**: explain what we expect. why we compare low vs low and high vs high.
low: expect similar amount of filled values.
high : ? 

compared filled vs detected for low

```{r}
a <- det[, which(grp == "low")]
b <- fil[, which(grp == "low")]
keep <- is.na(rowSums(det))

plot(rowMeans(log2(a), na.rm = TRUE)[keep],
     rowMeans(log2(b), na.rm = TRUE)[keep],
     xlab = "detected", ylab = "filled")
grid()
abline(0, 1, col = "grey")
```

Same for high

```{r}
a <- det[, which(grp == "high")]
b <- fil[, which(grp == "high")]
keep <- is.na(rowSums(det))

plot(rowMeans(log2(a), na.rm = TRUE)[keep],
     rowMeans(log2(b), na.rm = TRUE)[keep],
     xlab = "detected", ylab = "filled")
grid()
abline(0, 1, col = "grey")
```

# Post processing

## CV- based filtering

```{r}
idx_low <- grp == "low"

res_cv <- data.frame(low = rowRsd(featureValues(std_data)[, idx_low]), 
                     high = rowRsd(featureValues(std_data)[, !idx_low]))

dens <- apply(res_cv, 2, density, na.rm = TRUE)

plot(NA, xlim=range(sapply(dens, "[[", "x")), ylim=range(sapply(dens, "[[", "y")),
     xlab = "X", ylab = "Density", main = "Density Curves with Fill")
cols <- rainbow(length(dens))
mapply(function(d, col) {
  polygon(d$x, d$y, col=adjustcolor(col, alpha.f=0.5), border=col)
}, dens, cols)
abline(v = 0.3, col = "red", lty = 2, lwd = 2)
legend("topright", legend=names(dens), fill=adjustcolor(cols, alpha.f=0.5))
```
oh that would remove a lot of features.

We filter based on the Qcs samples. because in our dataset we have 2 types of 
QCs we will do this in 2 steps (???)

```{r}
std_data_filt <- filterFeatures(std_data, RsdFilter(qcIndex = idx_low, 
                                                   threshold = 0.3))

std_data_filt <- filterFeatures(std_data_filt, RsdFilter(qcIndex = !idx_low, 
                                                   threshold = 0.3))
```
**Notes**: Idk if you want to keep that. as you want !
Also there is a MissingValueFilter that could be nice here ? especially because
there is SO many features.
Maybe mention that usually we would run the CV one after normalisation no ?

# Data export

-  `SummarizedExperiment`: why is that a good data container.

```{r}
#' Extract results as a SummarizedExperiment
res <- quantify(std_data, method = "sum", filled = FALSE)
res
```


```{r}
library(SummarizedExperiment)
assays(res)$raw_filled <- featureValues(std_data, method = "sum",
                                        filled = TRUE )

#' Different assay in the SummarizedExperiment object
assayNames(res)
```

```{r}
assay(res, "raw_filled") |> head()
```

- Feature abundance matrix into xlsx

```{r}
write.csv (assay(res, "raw_filled"),
          file = "data/standards_abundance.csv",
          row.names = TRUE)
```

- MS2 spectra for all MS1 peaks: can be used as input into many software

```{r}
sp <- chromPeakSpectra(std_data)

library(MsBackendMgf)
export(sp, MsBackendMgf(), file = "std_spectra.mgf")
```


# Session information

```{r}
sessionInfo()
```
