---
title: "LC-MS data processing using *xcms*"
format:
  html:
    toc: true
    self-contained: true
author: "Marilyn De Graeve, Philippine Louail, Johannes Rainer"
code_folding: hide
editor: source
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

```{r setup, include=FALSE}
library(knitr)
library(quarto)
library(BiocStyle)
knitr::opts_knit$set(root.dir = './')
```


# Introduction

## Dataset description

This document outlines the preprocessing steps for an untargeted LC-MS/MS
metabolomics dataset. The samples consist of pooled human serum, each spiked
with known compounds at two different concentrations. These two different
concentration are categorized as high vs low. Each sample was measured three
times to ensure reproducibility.

Alongside the LC-MS data used for quantification, additional LC-MS/MS data was
acquired for each sample using a data-dependent acquisition (DDA) method.

## Data analysis description

This workflow processes LC-MS/MS data using a combination of R packages
designed for metabolomics analysis.

-   *Spectra* handles the raw mass spectrometry data.

-   *MsExperiment* manages the experimental design and links sample metadata
    with the raw data.

-   *xcms* performs the preprocessing steps, such as peak detection, alignment,
    and grouping. [ref to xcms preprint]

-   Additional packages are used for plotting, loading data tables, and utility
    functions.

The workflow is implemented as a *quarto* document... [TODO for jo: add some
information description of quarto, reproducible documents, literate
programming, advantage of using that system to build reproducible, data set
specific analysis workflows].


# Data import

- Define the experimental setup/data files. [TODO for jo: explain a bit why,
  what's needed, add a screenshot of the content in xlsx.]


1) Load all required R/Bioconductor libraries for the present analysis.

```{r}
#| message: false
library(xcms)
library(MsExperiment)
library(Spectra)
library(readxl)
library(RColorBrewer)
library(pheatmap)
library(MetaboCoreUtils)
```

2) Configure parallel processing. All data analysis functions in *xcms* have
   built-in parallel processing capabilities. In addition, to reduce memory
   load, *xcms* performs analyses in a *chunk-wise manner*, i.e. only data from
   a certain number of samples is loaded and processed at a time. This can be
   configured with the parameter `chunkSize = ` in most data analysis
   functions. Importantly, the number of CPU cores used should be smaller or
   equal to the value for this parameter. Below we chose to use 2 CPU cores for
   parallel processing. R supports on Unix systems the *multi-core* parallel
   processing, while on Windows systems *simple network of workstation*
   (SNOW)-based parallel processing must be used.

```{r}
cores <- 2
#' Set up parallel processing using 2 cores
if (.Platform$OS.type == "unix") {
    register(MulticoreParam(cores))
} else {
    register(SnowParam(cores))
}
```

3) Load experimental setup/sample information. It is good practice to define the
   experimental setup using e.g. a spread sheet that contains the names of all
   of the experiment's data files (eventually including their path) and their
   respective samples including all phenotypical information as well as
   technical/experimental properties. Ideally, the order of the samples should
   match their injection sequence. A screenshot of the spread sheet for the
   present experiment is shown in Figure XXX. Load the experiment's spread sheet
   using the `read_xlsx()` function from the *readxl* R package. The same
   `data.frame` could also be defined directly in R, but it is generally better,
   and more convenient to the user, to define such spreadsheet with as
   spreadsheet program.

```{r}
#' Import sample file
sample_data <- read_xlsx("data/standards_mzml.xlsx") |> as.data.frame()
```

4) Create a *data representation* for the experiment. The `readMsExperiment()`
   function takes the names of the data files (including the path to the
   directory where they are stored - configured below using the `MZML_PATH`
   variable) and a `data.frame` with the sample information for the respective
   data files as input. The resulting `MsExperiment` object (variable
   `sample_data`) contains a reference to the MS data files and the sample
   information.

```{r}
#' Define the path to the directory where the data files can be found
MZML_PATH <- file.path("data/mzML/")

#' Linking the raw data to its respective metadata.
std_data <- readMsExperiment(file.path(MZML_PATH, sample_data$mzML),
                             sampleData = sample_data)
```

Sample information can be extracted using the `sampleData()` function:

```{r}
#| tbl-cap: "Data files and samples."
sampleData(std_data)[, c("mzML", "sample_name", "mode", "collision_energy",
                         "concentration")] |>
    kable(format = "pipe")
```

5) Define colors to label individual - or sets of samples. For better
   visualization it is suggested to assign a color to each sample. These can be
   re-used in all plots during the analysis.

```{r}
#' Define colors
col_concentration <- c(low = "#FF7F00", high = "#A65628")
col_sample <- col_concentration[sampleData(std_data)$concentration]
```


# Initial data inspection

## Overview of full data

-   Describe why we should do that...


1) Create a base peak chromatogram (BPC) of the full data set and plot it. With
   parameter `aggregationFun = "max"` the maximum intensity per spectrum is
   reported, while setting `aggregationFun = "sum"` would sum-up all intensities
   per spectrum, hence generating a total ion chromatogram (TIC).

```{r}
#' Create a BPC
bpc <- chromatogram(std_data, aggregationFun = "max", chunkSize = cores)

#' Plot the BPC
plot(bpc, col = paste0(col_sample, 80))
grid()
abline(v = c(15, 225), lty = 2)
legend("topright", col = col_concentration, lty = 1,
       legend = names(col_concentration))
```

2) Filter the data set by retention time. Select the retention time range
   containing clear signal (@Marilyn: maybe there is a better way to describe
   this? would like to restrict the analysis to the part of the chromatogram
   where separation/retention is actually happening). This selection could be
   further solidified by evaluating the retention times of known compounds.

```{r}
std_data <- filterSpectra(std_data, filterRt, c(15, 225))
```

```{r, echo = FALSE}
#' Silently extract the BPC again - for reference later.
bpc <- chromatogram(std_data, aggregationFun = "max")
```


## Extracting EICs for known compounds

In addition to the general data evaluation above it is also strongly suggested
to closely inspect the LC-MS signal. This allows to immediately spot potential
problems with the data, ensure it is in *centroid* mode (which is a prerequisite
for the chromatographic peak detection algorithm used below) and helps to derive
parameter values for the various processing algorithms that will be used
later. Ideally, signal should be evaluated for several ions, which can include
ions of compounds that are expected to be present in the analyzed
samples. Preferentially, these compounds, which can also include internal
standards added to the sample mix, should have different retention times to
ensure signal along most of the retention time dimension is evaluated. In the
human serum samples analyzed here, we can expect metabolites such as proline,
serine, tryptophan to be present. We show this on the example of proline, but
the same code could be easily adapted for other compounds respectively expected
ions.

1) Determine the *m/z* range for proline: starting from its chemical formula,
   calculate the theoretical mass and subsequently the theoretical *m/z* for one
   of its ions. We use `"[M+H]+"` as the most likely adduct of proline in
   positive polarity, but could also specify any other possible adduct, such as
   `"[M+Na]+`, `"[M+NH4]+` etc. Create a range around the theoretical *m/z*
   by subtracting and adding a value of 0.01. Depending on the accuracy and
   precision of the MS instrument, this value might be increased or decreased.

```{r}
#' Calculate the mass of proline
proline_formula <- "C5H9NO2"
proline_mass <- calculateMass(proline_formula)

#' Calculate m/z for an adduct of proline
proline_mz <- mass2mz(proline_mass, c("[M+H]+"))[1, ]
proline_mzr <- cbind(mzmin = proline_mz - 0.01, mzmax = proline_mz + 0.01)
```

2) Extract and plot the EIC. If the expected retention time range is not known,
   parameter `rt` can also be omitted and the ion trace is extracted for the
   full full retention time range.

```{r}
proline_eic <- chromatogram(std_data, mz = proline_mzr)

plot(proline_eic, col = paste0(col_sample, 80))
```

- Multiple peaks are available. For the HPLC-MS setup we know that proline
  should elute at xxx seconds, so we zoom into that region.

```{r}
plot(proline_eic, col = paste0(col_sample, 80), xlim = c(165, 175))
```

This seems to make more sense...
**Notes**: I would justify the results above to subset the `proline_eic`
vairable to only samples where we see the peaks.
ALso i would keep the explanation of the 2 peaks and discuss it with the `bw`
param later down. even if they are far apart it still can be used i think.

We can also visualize the individual mass peaks for the \[M+H\]+ ion in the
first sample.

- check if data properly centroided

```{r}
std_data_sub <- std_data[1] |>
    filterSpectra(filterRt, c(167, 172)) |>
    filterSpectra(filterMzRange, proline_mzr[1, ])

plot(std_data_sub)
```

Above we visualize individual mass peaks in the m/z - retention time plane: evaluate
  whether data is in centroid mode and allows to determine variance in peaks'
  m/z along retention time axis.




```{r}
mz_diff <- spectra(std_data_sub) |>
    mz() |>
    unlist() |>
    diff()

max(mz_diff)
#' expressed in ppm...
```

-   Use this information to determine rt width and m/z deviation. e.g. `ppm=` ï¿½
    parameter for peak picking.

**Note** what to do when no information on known compounds is available? Select
area from BPC, extract full MS1 scan, select m/z range with e.g. high peak,
extract EIC from that. Maybe add that as a "Note".

# Data preprocessing

## Chromatographic peak detection

-   Derive settings: use the information from previous section. `peakwidth`:
    from the rule of thumb: half of the observed peak width to max double.
    Also, don't have too wise peak width.
-   `ppm` parameter: from above.
-   CentWave works with most LC-setups.

Peakwidth seems to be between 3-5 seconds. So we go for `peakwidth = c(2, 8)`

Difference between `integrate = 1` and `integrate = 2`? Should we mention that
or is it too much info/detail?

- We should just precise that we use = 2 because gaussian-ish shape.

- mention low snstresth

Same for proline:

```{r}
cwp <- CentWaveParam(peakwidth = c(2, 8), integrate = 2, snthresh = 1)

proline_eic <- findChromPeaks(proline_eic, param = cwp)
chromPeaks(proline_eic)

plot(proline_eic,
     peakCol = paste0(col_sample[chromPeaks(proline_eic)[, "column"]], 80),
     peakBg = paste0(col_sample[chromPeaks(proline_eic)[, "column"]], 40),
     col = col_sample, xlim = c(165, 180))
```

-  Explain why we use `snthresh = 5` instead of the default `snthresh = 10`.
    -   Because we have low intensity peaks, and we want to detect them.

```{r}
cwp <- CentWaveParam(peakwidth = c(2, 8),
                     ppm = 40,
                     snthresh = 5,
                     integrate = 2)
std_data <- findChromPeaks(std_data, param = cwp, chunkSize = cores)
```

Do peak refinement. Just mention in text that it is
suggested.because artifact artifact can be created, refinement
would fix that.

-   Performing peak merging.

```{r}
mnpp <- MergeNeighboringPeaksParam(expandRt = 3, expandMz = 0.002, ppm = 10,
                                   minProp = 0.8)
std_data <- refineChromPeaks(std_data, mnpp, chunkSize = cores)
```

-   Summary of identified peaks:
    -   number of peaks per sample.
    -   quantiles of retention time widths, m/z widths.

```{r}
#' Summary of identified peaks
data.frame(sample_name = sampleData(std_data)$sample_name,
           peak_count = as.integer(table(chromPeaks(std_data)[, "sample"]))) |>
  t() |>
  kable(format = "pipe")
```

## Retention time alignment

-   Initial correspondence: check settings. Serine might be great, because
    there is some shift.
    -   describe `bw` parameter: bandwidth for the peak density estimation.
        this can be looser in the initial correspondence step for alignment.

**Notes** Proline is a good example.

```{r}
grp <- sampleData(std_data)$concentration
grp[sampleData(std_data)$mode == "DDA"] <- NA
pdp <- PeakDensityParam(sampleGroups = grp,
                        bw = 4,
                        minFraction = 2/3,
                        binSize = 0.02,
                        ppm = 20)

a <- filterRt(proline_eic[1, ], c(160, 200))
plotChromPeakDensity(a[1, ], pdp)
```

-   For retention time alignment the grouping of chrom peaks to features does
    not need to be perfect, i.e. it is OK if signal from different ions is
    grouped into the same feature. We just use the feature's retention time to
    correct for (systematic) shifts in retention time between samples.
-   Settings OK because we group the rt-shifted chrom peaks into the same
    feature.

Apply settings.

```{r}
#' Initial correspondence
std_data <- groupChromPeaks(std_data, pdp)
```

-   Alignment. Explain parameter `span`... `extraPeaks` and `minFraction` used
    to define the *anchor peaks*, `extraPeaks`: number of peaks per feature,
    should be large. `minFraction`...

```{r}
pgp <- PeakGroupsParam(minFraction = 6 / 8, extraPeaks = 50, span = 0.4)
std_data <- adjustRtime(std_data, pgp, chunkSize = cores)

plotAdjustedRtime(std_data)

bpc_adj <- chromatogram(std_data, chromPeaks = "none", aggregationFun = "max")

par(mfrow = c(2, 1))
plot(bpc, col = paste0(col_sample, 60))
grid()
plot(bpc_adj, col = paste0(col_sample, 60))
grid()
```

Hm, does not seem to be particularly good. Let's extract the serine and proline
again.

- we can describe that is seem to be working up until 180s but after
  that not really.
- what could be the potential steps to fix this (finding anchor peaks in that
  area) but i would live it at that.
  - then check in proline example.

```{r}
proline_eic_adj <- chromatogram(std_data, mz = proline_mzr)

par(mfrow = c(2, 1))
plot(proline_eic[1, ], col = paste0(col_sample, 80),
     peakType = "none", xlim = c(160, 200))
plot(proline_eic_adj[1, ], col = paste0(col_sample, 80),
     peakType = "none", xlim = c(160, 200))
```

Signal, including MS2 seems to be better aligned.

We then apply these retention time.

```{r}
std_data <- applyAdjustedRtime(std_data)
```


Quantify similarity of BPC between samples.

## Correspondence analysis

For correspondence, use now more stringent settings for retention time
differences.

- mention `bw` here again, and that it should be stricter than in
the alignment step. e.g. because we expect the peaks of one feature to be closer
to eachother.

-   explain we are testing the new parameters below
-   explain the `simulate` parameter.

```{r}
pdp <- PeakDensityParam(sampleGroups = grp,
                        bw = 3,
                        minFraction = 2/3,
                        binSize = 0.02,
                        ppm = 20)

proline_eic_adj <- chromatogram(std_data, mz = proline_mzr, rt =
                                  cbind(rep(150, 3), rep(200, 3)))

plotChromPeakDensity(proline_eic_adj[1, ], param= pdp,  simulate = FALSE)
```
Nice grouping so we apply to full data:

```{r}
std_data <- groupChromPeaks(std_data, pdp)
```


## Gap filling

```{r}
sum(is.na(featureValues(std_data)))

std_data <- fillChromPeaks(std_data, ChromPeakAreaParam())
sum(is.na(featureValues(std_data)))
```

Compare filled data to detected values.

```{r}
det <- featureValues(std_data, filled = FALSE)
fil <- featureValues(std_data)
fil[!is.na(det)] <- NA

boxplot(log2(det))
boxplot(log2(fil))
```

**Notes**: explain what we expect. why we compare low vs low and high vs high.
low: expect similar amount of filled values.
high : ?

compared filled vs detected for low

```{r}
a <- det[, which(grp == "low")]
b <- fil[, which(grp == "low")]
keep <- is.na(rowSums(det))

plot(rowMeans(log2(a), na.rm = TRUE)[keep],
     rowMeans(log2(b), na.rm = TRUE)[keep],
     xlab = "detected", ylab = "filled")
grid()
abline(0, 1, col = "grey")
```

Same for high

```{r}
a <- det[, which(grp == "high")]
b <- fil[, which(grp == "high")]
keep <- is.na(rowSums(det))

plot(rowMeans(log2(a), na.rm = TRUE)[keep],
     rowMeans(log2(b), na.rm = TRUE)[keep],
     xlab = "detected", ylab = "filled")
grid()
abline(0, 1, col = "grey")
```

# Post processing

## CV- based filtering

```{r}
idx_low <- grp == "low"

res_cv <- data.frame(low = rowRsd(featureValues(std_data)[, idx_low]),
                     high = rowRsd(featureValues(std_data)[, !idx_low]))

dens <- apply(res_cv, 2, density, na.rm = TRUE)

plot(NA, xlim=range(sapply(dens, "[[", "x")), ylim=range(sapply(dens, "[[", "y")),
     xlab = "X", ylab = "Density", main = "Density Curves with Fill")
cols <- rainbow(length(dens))
mapply(function(d, col) {
  polygon(d$x, d$y, col=adjustcolor(col, alpha.f=0.5), border=col)
}, dens, cols)
abline(v = 0.3, col = "red", lty = 2, lwd = 2)
legend("topright", legend=names(dens), fill=adjustcolor(cols, alpha.f=0.5))
```
oh that would remove a lot of features.

We filter based on the Qcs samples. because in our dataset we have 2 types of
QCs we will do this in 2 steps (???)

```{r}
std_data_filt <- filterFeatures(std_data, RsdFilter(qcIndex = idx_low,
                                                   threshold = 0.3))

std_data_filt <- filterFeatures(std_data_filt, RsdFilter(qcIndex = !idx_low,
                                                   threshold = 0.3))
```
**Notes**: Idk if you want to keep that. as you want !
Also there is a MissingValueFilter that could be nice here ? especially because
there is SO many features.
Maybe mention that usually we would run the CV one after normalisation no ?

# Data export

-  `SummarizedExperiment`: why is that a good data container.

```{r}
#' Extract results as a SummarizedExperiment
res <- quantify(std_data, method = "sum", filled = FALSE)
res
```


```{r}
library(SummarizedExperiment)
assays(res)$raw_filled <- featureValues(std_data, method = "sum",
                                        filled = TRUE )

#' Different assay in the SummarizedExperiment object
assayNames(res)
```

```{r}
assay(res, "raw_filled") |> head()
```

- Feature abundance matrix into xlsx

```{r}
write.csv (assay(res, "raw_filled"),
          file = "data/standards_abundance.csv",
          row.names = TRUE)
```

- MS2 spectra for all MS1 peaks: can be used as input into many software

```{r}
sp <- chromPeakSpectra(std_data)

library(MsBackendMgf)
export(sp, MsBackendMgf(), file = "std_spectra.mgf")
```


# Session information

```{r}
sessionInfo()
```
